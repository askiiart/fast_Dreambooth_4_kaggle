{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-04T12:11:04.299771Z",
     "iopub.status.busy": "2022-11-04T12:11:04.299369Z",
     "iopub.status.idle": "2022-11-04T12:11:04.346400Z",
     "shell.execute_reply": "2022-11-04T12:11:04.345533Z",
     "shell.execute_reply.started": "2022-11-04T12:11:04.299686Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:11:10.980597Z",
     "iopub.status.busy": "2022-11-04T12:11:10.980238Z",
     "iopub.status.idle": "2022-11-04T12:14:04.966694Z",
     "shell.execute_reply": "2022-11-04T12:14:04.964949Z",
     "shell.execute_reply.started": "2022-11-04T12:11:10.980567Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:14:37.562140Z",
     "iopub.status.busy": "2022-11-04T12:14:37.561700Z",
     "iopub.status.idle": "2022-11-04T12:14:38.555797Z",
     "shell.execute_reply": "2022-11-04T12:14:38.554497Z",
     "shell.execute_reply.started": "2022-11-04T12:14:37.562103Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:14:40.125401Z",
     "iopub.status.busy": "2022-11-04T12:14:40.125009Z",
     "iopub.status.idle": "2022-11-04T12:14:41.084148Z",
     "shell.execute_reply": "2022-11-04T12:14:41.082843Z",
     "shell.execute_reply.started": "2022-11-04T12:14:40.125364Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:14:42.730615Z",
     "iopub.status.busy": "2022-11-04T12:14:42.729271Z",
     "iopub.status.idle": "2022-11-04T12:14:43.734213Z",
     "shell.execute_reply": "2022-11-04T12:14:43.732876Z",
     "shell.execute_reply.started": "2022-11-04T12:14:42.730565Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/gdrive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:14:46.192315Z",
     "iopub.status.busy": "2022-11-04T12:14:46.191929Z",
     "iopub.status.idle": "2022-11-04T12:14:46.201995Z",
     "shell.execute_reply": "2022-11-04T12:14:46.200995Z",
     "shell.execute_reply.started": "2022-11-04T12:14:46.192281Z"
    }
   },
   "outputs": [],
   "source": [
    "cd /kaggle/working/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:14:49.480941Z",
     "iopub.status.busy": "2022-11-04T12:14:49.480374Z",
     "iopub.status.idle": "2022-11-04T12:15:41.911053Z",
     "shell.execute_reply": "2022-11-04T12:15:41.909754Z",
     "shell.execute_reply.started": "2022-11-04T12:14:49.480881Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/TheLastBen/diffusers\n",
    "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
    "!pip install -q accelerate==0.12.0\n",
    "!pip install -q OmegaConf\n",
    "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:15:48.165770Z",
     "iopub.status.busy": "2022-11-04T12:15:48.165365Z",
     "iopub.status.idle": "2022-11-04T12:15:53.728230Z",
     "shell.execute_reply": "2022-11-04T12:15:53.727121Z",
     "shell.execute_reply.started": "2022-11-04T12:15:48.165725Z"
    }
   },
   "outputs": [],
   "source": [
    "!mv Deps Deps.7z\n",
    "!7z x Deps.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:21:03.796914Z",
     "iopub.status.busy": "2022-11-04T12:21:03.796481Z",
     "iopub.status.idle": "2022-11-04T12:21:04.754477Z",
     "shell.execute_reply": "2022-11-04T12:21:04.753282Z",
     "shell.execute_reply.started": "2022-11-04T12:21:03.796857Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/working/content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:17:36.475885Z",
     "iopub.status.busy": "2022-11-04T12:17:36.475459Z",
     "iopub.status.idle": "2022-11-04T12:17:38.397787Z",
     "shell.execute_reply": "2022-11-04T12:17:38.396714Z",
     "shell.execute_reply.started": "2022-11-04T12:17:36.475847Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm /kaggle/working/content/Deps.7z\n",
    "!rm -r /kaggle/working/content/usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:50:47.695661Z",
     "iopub.status.busy": "2022-11-04T12:50:47.694773Z",
     "iopub.status.idle": "2022-11-04T12:50:59.460924Z",
     "shell.execute_reply": "2022-11-04T12:50:59.459727Z",
     "shell.execute_reply.started": "2022-11-04T12:50:47.695612Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:51:07.552453Z",
     "iopub.status.busy": "2022-11-04T12:51:07.552049Z",
     "iopub.status.idle": "2022-11-04T12:51:25.559237Z",
     "shell.execute_reply": "2022-11-04T12:51:25.558160Z",
     "shell.execute_reply.started": "2022-11-04T12:51:07.552415Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown # xformers\n",
    "\n",
    "from subprocess import getoutput\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "import wget\n",
    "import time\n",
    "\n",
    "s = getoutput('nvidia-smi')\n",
    "if 'T4' in s:\n",
    "  gpu = 'T4'\n",
    "elif 'P100' in s:\n",
    "  gpu = 'P100'\n",
    "elif 'V100' in s:\n",
    "  gpu = 'V100'\n",
    "elif 'A100' in s:\n",
    "  gpu = 'A100'\n",
    "\n",
    "while True:\n",
    "    try: \n",
    "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
    "        break\n",
    "    except:\n",
    "        pass\n",
    "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
    "    time.sleep(5)\n",
    "\n",
    "if (gpu=='T4'):\n",
    "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
    "  \n",
    "elif (gpu=='P100'):\n",
    "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
    "\n",
    "elif (gpu=='V100'):\n",
    "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
    "\n",
    "elif (gpu=='A100'):\n",
    "  %cd /usr/local/lib/python3.7/diffusers/models/\n",
    "  !rm /usr/local/lib/python3.7/diffusers/models/attention.py\n",
    "  wget.download('https://raw.githubusercontent.com/huggingface/diffusers/269109dbfbbdbe2800535239b881e96e1828a0ef/src/diffusers/models/attention.py') \n",
    "\n",
    "clear_output()\n",
    "print('\u001b[1;32mDONE !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:52:33.957486Z",
     "iopub.status.busy": "2022-11-04T12:52:33.957095Z",
     "iopub.status.idle": "2022-11-04T12:52:33.963066Z",
     "shell.execute_reply": "2022-11-04T12:52:33.962030Z",
     "shell.execute_reply.started": "2022-11-04T12:52:33.957450Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:52:36.146045Z",
     "iopub.status.busy": "2022-11-04T12:52:36.145392Z",
     "iopub.status.idle": "2022-11-04T12:52:36.153984Z",
     "shell.execute_reply": "2022-11-04T12:52:36.151876Z",
     "shell.execute_reply.started": "2022-11-04T12:52:36.146005Z"
    }
   },
   "outputs": [],
   "source": [
    "cd /kaggle/working/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T12:52:38.561257Z",
     "iopub.status.busy": "2022-11-04T12:52:38.560906Z",
     "iopub.status.idle": "2022-11-04T12:52:45.499302Z",
     "shell.execute_reply": "2022-11-04T12:52:45.498173Z",
     "shell.execute_reply.started": "2022-11-04T12:52:38.561228Z"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install git-lfs\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:21:35.356078Z",
     "iopub.status.busy": "2022-11-04T13:21:35.355697Z",
     "iopub.status.idle": "2022-11-04T13:26:17.964694Z",
     "shell.execute_reply": "2022-11-04T13:26:17.963108Z",
     "shell.execute_reply.started": "2022-11-04T13:21:35.356040Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "\n",
    "#@markdown - Skip this cell if you are loading a previous session\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "with capture.capture_output() as cap: \n",
    "  %cd /kaggle/working/content/\n",
    "\n",
    "Huggingface_Token = \"your_huggingface_token\" #@param {type:\"string\"}\n",
    "token=Huggingface_Token\n",
    "\n",
    "#@markdown (Make sure you've accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5)\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown Or\n",
    "\n",
    "CKPT_Path = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Or\n",
    "\n",
    "CKPT_Link = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown - A CKPT direct link, huggingface CKPT link or a shared CKPT from gdrive.\n",
    "#@markdown ---\n",
    "\n",
    "Compatiblity_Mode=\"False\" #@param {type:\"boolean\"}\n",
    "#@markdown - Enable only if you're getting conversion errors.\n",
    "\n",
    "\n",
    "def downloadmodel():\n",
    "  token=Huggingface_Token\n",
    "  if token==\"\":\n",
    "      token=input(\"Insert your huggingface token :\")\n",
    "  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "    !rm -r /kaggle/working/content/stable-diffusion-v1-5\n",
    "  clear_output()\n",
    "\n",
    "  %cd /kaggle/working/content/\n",
    "  clear_output()\n",
    "  !mkdir /kaggle/working/content/stable-diffusion-v1-5\n",
    "  %cd /kaggle/working/content/stable-diffusion-v1-5\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
    "    !mv /kaggle/working/content/stable-diffusion-v1-5/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-v1-5/vae\n",
    "    !rm -r /kaggle/working/content/stable-diffusion-v1-5/.git\n",
    "    %cd /kaggle/working/content/    \n",
    "    clear_output()\n",
    "    print('\u001b[1;32mDONE !')\n",
    "  else:\n",
    "    while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
    "         time.sleep(5)\n",
    "        \n",
    "if CKPT_Path !=\"\":\n",
    "  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "    !rm -r /kaggle/working/content/stable-diffusion-v1-5\n",
    "  if os.path.exists(str(CKPT_Path)):\n",
    "    !mkdir /kaggle/working/content/stable-diffusion-v1-5\n",
    "    with capture.capture_output() as cap:\n",
    "      if Compatiblity_Mode:\n",
    "        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
    "        !python /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /kaggle/working/content/stable-diffusion-v1-5\n",
    "        !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n",
    "      else:           \n",
    "        !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /kaggle/working/content/stable-diffusion-v1-5        \n",
    "    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm /kaggle/working/content/v1-inference.yaml\n",
    "      clear_output()\n",
    "      print('\u001b[1;32mDONE !')\n",
    "    else:\n",
    "      !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n",
    "      !rm /kaggle/working/content/v1-inference.yaml\n",
    "      !rm -r /kaggle/working/content/stable-diffusion-v1-5\n",
    "      while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4.7GB CKPT instead of 7GB')\n",
    "        time.sleep(5)\n",
    "  else:\n",
    "    while not os.path.exists(str(CKPT_Path)):\n",
    "       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
    "       time.sleep(5)\n",
    "\n",
    "\n",
    "elif CKPT_Link !=\"\":   \n",
    "    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "      !rm -r /kaggle/working/content/stable-diffusion-v1-5     \n",
    "    !gdown --fuzzy $CKPT_Link -O model.ckpt    \n",
    "    if os.path.exists('/kaggle/working/content/model.ckpt'):\n",
    "      if os.path.getsize(\"/kaggle/working/content/model.ckpt\") > 1810671599:\n",
    "        !mkdir /kaggle/working/content/stable-diffusion-v1-5\n",
    "        with capture.capture_output() as cap: \n",
    "          if Compatiblity_Mode:\n",
    "            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
    "            !python /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /kaggle/working/content/model.ckpt --dump_path /kaggle/working/content/stable-diffusion-v1-5\n",
    "            !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py            \n",
    "          else:           \n",
    "            !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /kaggle/working/content/model.ckpt --dump_path /kaggle/working/content/stable-diffusion-v1-5\n",
    "        if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "          clear_output()\n",
    "          print('\u001b[1;32mDONE !')\n",
    "          !rm /kaggle/working/content/v1-inference.yaml\n",
    "          !rm /kaggle/working/content/model.ckpt\n",
    "        else:\n",
    "          if os.path.exists('/kaggle/working/content/v1-inference.yaml'):\n",
    "            !rm /kaggle/working/content/v1-inference.yaml\n",
    "          !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n",
    "          !rm -r /kaggle/working/content/stable-diffusion-v1-5\n",
    "          !rm /kaggle/working/content/model.ckpt\n",
    "          while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4.7GB CKPT instead of 7GB')\n",
    "            time.sleep(5)\n",
    "      else:\n",
    "        while os.path.getsize('/kaggle/working/content/model.ckpt') < 1810671599:\n",
    "           print('\u001b[1;31mWrong link, check that the link is valid')\n",
    "           time.sleep(5)\n",
    "else:\n",
    "  downloadmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:36:19.741965Z",
     "iopub.status.busy": "2022-11-04T13:36:19.741559Z",
     "iopub.status.idle": "2022-11-04T13:36:20.693190Z",
     "shell.execute_reply": "2022-11-04T13:36:20.691872Z",
     "shell.execute_reply.started": "2022-11-04T13:36:19.741927Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:44:15.041151Z",
     "iopub.status.busy": "2022-11-04T13:44:15.040115Z",
     "iopub.status.idle": "2022-11-04T13:44:15.994822Z",
     "shell.execute_reply": "2022-11-04T13:44:15.993477Z",
     "shell.execute_reply.started": "2022-11-04T13:44:15.041107Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:45:39.172813Z",
     "iopub.status.busy": "2022-11-04T13:45:39.171769Z",
     "iopub.status.idle": "2022-11-04T13:45:40.170377Z",
     "shell.execute_reply": "2022-11-04T13:45:40.168884Z",
     "shell.execute_reply.started": "2022-11-04T13:45:39.172772Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:50:37.722294Z",
     "iopub.status.busy": "2022-11-04T13:50:37.721747Z",
     "iopub.status.idle": "2022-11-04T13:50:38.719514Z",
     "shell.execute_reply": "2022-11-04T13:50:38.718242Z",
     "shell.execute_reply.started": "2022-11-04T13:50:37.722229Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/instance_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:52:04.989606Z",
     "iopub.status.busy": "2022-11-04T13:52:04.989063Z",
     "iopub.status.idle": "2022-11-04T13:52:05.967149Z",
     "shell.execute_reply": "2022-11-04T13:52:05.965872Z",
     "shell.execute_reply.started": "2022-11-04T13:52:04.989555Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/Regularization_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T13:55:40.114120Z",
     "iopub.status.busy": "2022-11-04T13:55:40.113659Z",
     "iopub.status.idle": "2022-11-04T13:55:54.141316Z",
     "shell.execute_reply": "2022-11-04T13:55:54.139427Z",
     "shell.execute_reply.started": "2022-11-04T13:55:40.114067Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "import wget\n",
    "import time\n",
    "\n",
    "#@markdown #NEW FAST METHOD\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "Use_New_Fast_Method= \"Yes\" #@param [\"Yes\", \"No\"]\n",
    "\n",
    "if Use_New_Fast_Method==\"Yes\":\n",
    "\n",
    "  def fdownloadmodel():\n",
    "    token=input(\"Insert your huggingface token :\")\n",
    "    %cd /kaggle/working/content/\n",
    "    !mkdir /kaggle/working/content/stable-diffusion-v1-5\n",
    "    %cd /kaggle/working/content/stable-diffusion-v1-5\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "      !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
    "      !mv /kaggle/working/content/stable-diffusion-v1-5/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-v1-5/vae\n",
    "      !rm -r /kaggle/working/content/stable-diffusion-v1-5/.git\n",
    "      %cd /kaggle/working/content/    \n",
    "      clear_output()\n",
    "\n",
    "  MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v1-5\"\n",
    "  PT=\"\"\n",
    "\n",
    "  Captionned_instance_images = True\n",
    "  Save_class_images_to_gdrive = False\n",
    "  With_Prior_Preservation = \"No\"\n",
    "  \n",
    "  #@markdown - If you accidentally run the old method cell below, you need to run this cell again but no need to reupload images if they are already uploaded.\n",
    "  \n",
    "  Session_Name = \"your_instance_name\" #@param{type: 'string'}\n",
    "  while Session_Name==\"\":\n",
    "    print('\u001b[1;31mInput the Session Name:') \n",
    "    Session_Name=input('')\n",
    "  INSTANCE_NAME=Session_Name\n",
    "  WORKSPACE='/kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth'\n",
    "  OUTPUT_DIR=\"/kaggle/working/content/models/\"+Session_Name\n",
    "  SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
    "  INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
    "  MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
    "  CLASS_DIR=SESSION_DIR+'/Regularization_images'\n",
    "\n",
    "  #@markdown - Create or Load a session, just enter its name, it if it exists, it will load it, otherwise it'll create an new session.\n",
    "\n",
    "\n",
    "  Contains_faces = \"No\" #@param [\"No\", \"Female\", \"Male\", \"Both\"]\n",
    "\n",
    "  def reg():\n",
    "    if Contains_faces!=\"No\":\n",
    "      if not os.path.exists(str(CLASS_DIR)):\n",
    "        with capture.capture_output() as cap:\n",
    "          %mkdir -p \"$CLASS_DIR\"\n",
    "          !wget 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Women'\n",
    "          !wget 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Men'\n",
    "          !wget 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Mix'\n",
    "          %cd $CLASS_DIR\n",
    "          !unzip /kaggle/working/content/Men\n",
    "          !unzip /kaggle/working/content/Women\n",
    "          !unzip /kaggle/working/content/Mix\n",
    "          %cd /kaggle/working/content\n",
    "          !rm Men Women Mix\n",
    "      with capture.capture_output() as cap:\n",
    "        %cd \"$CLASS_DIR\"\n",
    "        !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
    "        %cd /kaggle/working/content                \n",
    "\n",
    "#@markdown - If you're training on a subject with a face or a movie/style that contains faces. (experimental, still needs some tuning) \n",
    "\n",
    "  if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
    "    print('\u001b[1;32mLoading session with no previous model, using the original model')\n",
    "    reg()\n",
    "    if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "      if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "        !rm -r '/kaggle/working/content/stable-diffusion-v1-5'    \n",
    "      fdownloadmodel()\n",
    "    if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "      print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
    "    else:\n",
    "      print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
    "\n",
    "  elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
    "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
    "    reg()\n",
    "    %mkdir -p \"$OUTPUT_DIR\"\n",
    "    !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\" --session_dir \"$SESSION_DIR\"\n",
    "    if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "      resume=True    \n",
    "      !rm /kaggle/working/content/v1-inference.yaml\n",
    "      clear_output()\n",
    "      print('\u001b[1;32mSession loaded.')\n",
    "    else:     \n",
    "      !rm /kaggle/working/content/v1-inference.yaml\n",
    "      if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
    "\n",
    "\n",
    "  elif not os.path.exists(str(SESSION_DIR)):\n",
    "      %mkdir -p \"$INSTANCE_DIR\"\n",
    "      print('\u001b[1;32mCreating session...')\n",
    "      reg()\n",
    "      if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "        if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "          !rm -r '/kaggle/working/content/stable-diffusion-v1-5'\n",
    "        fdownloadmodel()\n",
    "      if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001b[1;32mSession created, proceed to uploading instance images')\n",
    "      else:\n",
    "        print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n",
    "      \n",
    "  if Contains_faces == \"Female\":\n",
    "    CLASS_DIR=CLASS_DIR+'/Women'\n",
    "  if Contains_faces == \"Male\":\n",
    "    CLASS_DIR=CLASS_DIR+'/Men'\n",
    "  if Contains_faces == \"Both\":\n",
    "    CLASS_DIR=CLASS_DIR+'/Mix'\n",
    "\n",
    "      #@markdown \n",
    "\n",
    "      #@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n",
    "      #@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
    "      #@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg\n",
    "      \n",
    "else:\n",
    "  print('\u001b[1;32mOk, proceed to the old method cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:01:54.565431Z",
     "iopub.status.busy": "2022-11-04T14:01:54.564948Z",
     "iopub.status.idle": "2022-11-04T14:01:59.639084Z",
     "shell.execute_reply": "2022-11-04T14:01:59.637735Z",
     "shell.execute_reply.started": "2022-11-04T14:01:54.565385Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown #Instance Images\n",
    "#@markdown ----\n",
    "\n",
    "#@markdown\n",
    "#@markdown - Run the cell to Upload the instance pictures.\n",
    "\n",
    "if Use_New_Fast_Method==\"Yes\":\n",
    "\n",
    "  Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
    "  #@markdown - Uncheck the box to keep the existing instance images.\n",
    "\n",
    "\n",
    "  if Remove_existing_instance_images:\n",
    "    if os.path.exists(str(INSTANCE_DIR)):\n",
    "      !rm -r \"$INSTANCE_DIR\"\n",
    "\n",
    "  if not os.path.exists(str(INSTANCE_DIR)):\n",
    "    %mkdir -p \"$INSTANCE_DIR\"\n",
    "\n",
    "  IMAGES_FOLDER_OPTIONAL=\"/kaggle/input/your_images_data_folder_path\" #@param{type: 'string'}\n",
    "\n",
    "\n",
    "  #@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n",
    "\n",
    "  while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
    "    print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
    "    IMAGES_FOLDER_OPTIONAL=input('')\n",
    "\n",
    "  if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
    "    with capture.capture_output() as cap:\n",
    "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/.\" \"$INSTANCE_DIR\"\n",
    "      %cd \"$INSTANCE_DIR\"\n",
    "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
    "      %cd /content\n",
    "      if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "        %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"      \n",
    "    print('\u001b[1;32mDone, proceed to the training cell')\n",
    "\n",
    "  elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
    "    uploaded = files.upload()\n",
    "    for filename in uploaded.keys():\n",
    "      shutil.move(filename, INSTANCE_DIR)\n",
    "      clear_output()\n",
    "\n",
    "    with capture.capture_output() as cap:\n",
    "      %cd \"$INSTANCE_DIR\"\n",
    "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
    "      %cd /content\n",
    "      if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "        %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"\n",
    "    print('\u001b[1;32mDone, proceed to the training cell')\n",
    "\n",
    "else:\n",
    "  print(('\u001b[1;31mSet the New_Fast_Method to Yes to use this cell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:14:30.616528Z",
     "iopub.status.busy": "2022-11-04T14:14:30.616118Z",
     "iopub.status.idle": "2022-11-04T14:14:30.623622Z",
     "shell.execute_reply": "2022-11-04T14:14:30.622121Z",
     "shell.execute_reply.started": "2022-11-04T14:14:30.616492Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:17:03.108641Z",
     "iopub.status.busy": "2022-11-04T14:17:03.108137Z",
     "iopub.status.idle": "2022-11-04T14:17:20.283075Z",
     "shell.execute_reply": "2022-11-04T14:17:20.281811Z",
     "shell.execute_reply.started": "2022-11-04T14:17:03.108604Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:17:27.023065Z",
     "iopub.status.busy": "2022-11-04T14:17:27.021959Z",
     "iopub.status.idle": "2022-11-04T14:17:37.031611Z",
     "shell.execute_reply": "2022-11-04T14:17:37.030258Z",
     "shell.execute_reply.started": "2022-11-04T14:17:27.023008Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:17:46.128985Z",
     "iopub.status.busy": "2022-11-04T14:17:46.127834Z",
     "iopub.status.idle": "2022-11-04T14:17:56.582611Z",
     "shell.execute_reply": "2022-11-04T14:17:56.581136Z",
     "shell.execute_reply.started": "2022-11-04T14:17:46.128928Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:18:00.492493Z",
     "iopub.status.busy": "2022-11-04T14:18:00.492064Z",
     "iopub.status.idle": "2022-11-04T14:18:14.289698Z",
     "shell.execute_reply": "2022-11-04T14:18:14.288369Z",
     "shell.execute_reply.started": "2022-11-04T14:18:00.492455Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:18:17.539549Z",
     "iopub.status.busy": "2022-11-04T14:18:17.538793Z",
     "iopub.status.idle": "2022-11-04T14:18:17.546938Z",
     "shell.execute_reply": "2022-11-04T14:18:17.545965Z",
     "shell.execute_reply.started": "2022-11-04T14:18:17.539509Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:18:19.763498Z",
     "iopub.status.busy": "2022-11-04T14:18:19.763103Z",
     "iopub.status.idle": "2022-11-04T14:18:19.822589Z",
     "shell.execute_reply": "2022-11-04T14:18:19.821716Z",
     "shell.execute_reply.started": "2022-11-04T14:18:19.763463Z"
    }
   },
   "outputs": [],
   "source": [
    "import ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T14:18:22.752801Z",
     "iopub.status.busy": "2022-11-04T14:18:22.752449Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown ---\n",
    "#@markdown #Start DreamBooth\n",
    "#@markdown ---\n",
    "import os\n",
    "from subprocess import getoutput\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "\n",
    "Resume_Training = False #@param {type:\"boolean\"}\n",
    "\n",
    "if not Resume_Training and not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n",
    "    !rm -r '/kaggle/working/content/stable-diffusion-v1-5'\n",
    "  print('\u001b[1;31mOriginal model not found, downloading....\u001b[0m')\n",
    "  fdownloadmodel()\n",
    "  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "     print('\u001b[1;32mModel downloaded, proceeding to training...')\n",
    "  else:\n",
    "     print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n",
    "\n",
    "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
    "\n",
    "MODELT_NAME=MODEL_NAME\n",
    "\n",
    "Training_Steps=3000 #@param{type: 'number'}\n",
    "#@markdown - Total Steps = Number of Instance images * 100, if you use 30 images, use 3000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
    "\n",
    "Seed=96576 #@param{type: 'number'}\n",
    "\n",
    "fp16 = True\n",
    "if fp16:\n",
    "  prec=\"fp16\"\n",
    "else:\n",
    "  prec=\"no\"\n",
    "\n",
    "s = getoutput('nvidia-smi')\n",
    "if 'A100' in s:\n",
    "  precision=\"no\"\n",
    "else:\n",
    "  precision=prec\n",
    "\n",
    "try:\n",
    "   resume\n",
    "   if resume and not Resume_Training:\n",
    "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
    "     while True:\n",
    "        ansres=input('')\n",
    "        if ansres=='no':\n",
    "          Resume_Training = True\n",
    "          del ansres\n",
    "          break\n",
    "        elif ansres=='yes':\n",
    "          Resume_Training = False\n",
    "          resume= False\n",
    "          break\n",
    "except:\n",
    "  pass\n",
    "\n",
    "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  MODELT_NAME=OUTPUT_DIR\n",
    "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
    "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
    "  MODELT_NAME=MODEL_NAME\n",
    "\n",
    "#@markdown ---------------------------\n",
    "\n",
    "try:\n",
    "   Contain_f\n",
    "   pass\n",
    "except:\n",
    "   Contain_f=Contains_faces\n",
    "\n",
    "Enable_text_encoder_training= True #@param{type: 'boolean'}\n",
    "\n",
    "#@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n",
    "#@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n",
    "\n",
    "#@markdown - Enter the % of the total steps for which to train the text_encoder\n",
    "Train_text_encoder_for=35 #@param{type: 'number'}\n",
    "\n",
    "#@markdown - Keep the % low for better style transfer, more training steps will be necessary for good results.\n",
    "#@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize, \n",
    "\n",
    "if Train_text_encoder_for>=100:\n",
    "  stptxt=Training_Steps\n",
    "elif Train_text_encoder_for==0:\n",
    "  Enable_text_encoder_training= False\n",
    "  stptxt=10\n",
    "else:\n",
    "  stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n",
    "\n",
    "if not Enable_text_encoder_training:\n",
    "  Contains_faces=\"No\"\n",
    "else:\n",
    "   Contains_faces=Contain_f\n",
    "\n",
    "if Enable_text_encoder_training:\n",
    "  Textenc=\"--train_text_encoder\"\n",
    "else:\n",
    "  Textenc=\"\"\n",
    "\n",
    "#@markdown ---------------------------\n",
    "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
    "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
    "if Save_Checkpoint_Every==None:\n",
    "  Save_Checkpoint_Every=1\n",
    "#@markdown - Minimum 200 steps between each save.\n",
    "stp=0\n",
    "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
    "if Start_saving_from_the_step==None:\n",
    "  Start_saving_from_the_step=0\n",
    "if (Start_saving_from_the_step < 200):\n",
    "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
    "stpsv=Start_saving_from_the_step\n",
    "if Save_Checkpoint_Every_n_Steps:\n",
    "  stp=Save_Checkpoint_Every\n",
    "#@markdown - Start saving intermediary checkpoints from this step.\n",
    "\n",
    "Caption=''\n",
    "if Captionned_instance_images:\n",
    "  Caption='--image_captions_filename'\n",
    "\n",
    "\n",
    "def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
    "  print('\u001b[1;33mTraining the text encoder with regularization...\u001b[0m')\n",
    "  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    --train_text_encoder \\\n",
    "    --dump_only_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --class_data_dir=\"$CLASS_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "    --instance_prompt=\"$PT\"\\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=2e-6 \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --center_crop \\\n",
    "    --max_train_steps=$Training_Steps \\\n",
    "    --num_class_images=200\n",
    "\n",
    "def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
    "  clear_output()\n",
    "  print('\u001b[1;33mTraining the unet...\u001b[0m')\n",
    "  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    --train_only_unet \\\n",
    "    --Session_dir=$SESSION_DIR \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=2e-6 \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --center_crop \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "if Contains_faces!=\"No\":\n",
    "  \n",
    "  txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
    "  unet_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n",
    "\n",
    "\n",
    "elif With_Prior_Preservation=='No':\n",
    "  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    $Textenc \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --stop_text_encoder_training=$stptxt \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --Session_dir=$SESSION_DIR \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=2e-6 \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --center_crop \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "elif With_Prior_Preservation=='Yes':\n",
    "\n",
    "  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    $Textenc \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --Session_dir=\"/kaggle/working/content/gdrive/MyDrive\" \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --class_data_dir=\"$CLASS_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "    --instance_prompt=\"$PT\"\\\n",
    "    --class_prompt=\"$CPT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=2e-6 \\\n",
    "    --lr_scheduler=\"constant\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --center_crop \\\n",
    "    --max_train_steps=$Training_Steps \\\n",
    "    --num_class_images=$SUBJECT_IMAGES\n",
    "\n",
    "\n",
    "if Save_class_images_to_gdrive:\n",
    "  if os.path.exists(str(CLASS_DIR)):\n",
    "    if not os.path.exists('/kaggle/working/content/gdrive/MyDrive/Class_images'):\n",
    "      !mkdir /kaggle/working/content/gdrive/MyDrive/Class_images\n",
    "    Class_gdir= '/kaggle/working/content/gdrive/MyDrive/Class_images/'+SUBJECT_TYPE\n",
    "    if not os.path.exists(str(Class_gdir)):\n",
    "      !cp -r \"$CLASS_DIR\" /kaggle/working/content/gdrive/MyDrive/Class_images\n",
    "\n",
    "if os.path.exists('/kaggle/working/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print(\"Almost done ...\")\n",
    "  %cd /kaggle/working/content    \n",
    "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
    "  clear_output()\n",
    "  if precision==\"no\":\n",
    "    !sed -i '226s@.*@@' /kaggle/working/content/convertosd.py\n",
    "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /kaggle/working/content/convertosd.py\n",
    "  if Use_New_Fast_Method==\"No\":\n",
    "    !sed -i '202s@.*@    checkpoint_path= \"/kaggle/working/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
    "  else:\n",
    "    !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
    "  !python /kaggle/working/content/convertosd.py\n",
    "  clear_output()\n",
    "  if Use_New_Fast_Method==\"No\":  \n",
    "    if os.path.exists('/kaggle/working/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'):\n",
    "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive\")\n",
    "    else:\n",
    "      print(\"\u001b[1;31mSomething went wrong\")\n",
    "  else:\n",
    "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
    "      if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
    "        !cp -R '/kaggle/working/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
    "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
    "    else:\n",
    "      print(\"\u001b[1;31mSomething went wrong\")\n",
    "    \n",
    "else:\n",
    "  print(\"\u001b[1;31mSomething went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /kaggle/working/content/gdrive/MyDrive/your_instance_name.ckpt /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'your_instance_name.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
